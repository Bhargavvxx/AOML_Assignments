{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import joblib\n",
    "\n",
    "# Enable IterativeImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Drop rows with missing target values\n",
    "train_df.dropna(subset=['output_electricity_generation'], inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['pressure_temp_interaction'] = df['vapour_pressure'] * df['vapour_temperature']\n",
    "    return df\n",
    "\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['day']\n",
    "numerical_cols = [col for col in train_df.columns if col not in ['uid', 'output_electricity_generation'] + categorical_cols]\n",
    "\n",
    "# Data Preprocessing\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Prepare data\n",
    "X = train_df.drop(columns=['uid', 'output_electricity_generation'])\n",
    "y = train_df['output_electricity_generation']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_valid = preprocessor.transform(X_valid)\n",
    "\n",
    "# Train models\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=300, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=300, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], callbacks=[lgb.early_stopping(50)], verbose=False)\n",
    "\n",
    "cb_model = cb.CatBoostRegressor(n_estimators=300, learning_rate=0.1, depth=5, verbose=0)\n",
    "cb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=50)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=5, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Stacking model\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[('xgb', xgb_model), ('lgb', lgb_model), ('cb', cb_model), ('rf', rf_model)],\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = stacking_model.predict(X_valid)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "print(f\"Stacking RMSE: {rmse}\")\n",
    "print(f\"Stacking MAE: {mae}\")\n",
    "print(f\"Stacking RÂ² Score: {r2}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(stacking_model, 'stacking_model.pkl')\n",
    "\n",
    "# Predict on test data\n",
    "test_df_preprocessed = preprocessor.transform(test_df.drop(columns=['uid']))\n",
    "final_preds = stacking_model.predict(test_df_preprocessed)\n",
    "\n",
    "# Save predictions\n",
    "output_df = pd.DataFrame({'uid': test_df['uid'], 'output_electricity_generation': final_preds})\n",
    "output_df.to_csv(\"final_predictions.csv\", index=False)\n",
    "print(\"Predictions saved to final_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
