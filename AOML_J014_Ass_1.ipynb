{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec4b70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=3, F1 Score: 0.5454545454545454\n",
      "K=5, F1 Score: 0.6037735849056604\n",
      "K=7, F1 Score: 0.6605504587155963\n",
      "Best K: 7, Best F1 Score: 0.6605504587155963\n",
      "max_depth=3, F1 Score: 0.6476190476190475\n",
      "max_depth=5, F1 Score: 0.6379310344827586\n",
      "max_depth=7, F1 Score: 0.5535714285714286\n",
      "Best max_depth: 3, Best F1 Score: 0.6476190476190475\n",
      "Sample 1 Prediction: [0]\n",
      "Sample 2 Prediction: [0]\n",
      "Sample 3 Prediction: [0]\n",
      "Sample 4 Prediction: [0]\n",
      "Sample 5 Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('https://github.com/plotly/datasets/raw/refs/heads/master/diabetes.csv')\n",
    "\n",
    "def bmi_category(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif bmi < 24.9:\n",
    "        return 'Normal'\n",
    "    elif bmi < 29.9:\n",
    "        return 'Overweight'\n",
    "    return 'Obese'\n",
    "\n",
    "df['BMI_category'] = df['BMI'].apply(bmi_category)\n",
    "\n",
    "# Splitting dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining feature types\n",
    "numeric_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Age']\n",
    "categorical_features = ['BMI_category']\n",
    "\n",
    "# Standardizing numeric features\n",
    "scaler = StandardScaler()\n",
    "train_df[numeric_features] = scaler.fit_transform(train_df[numeric_features])\n",
    "val_df[numeric_features] = scaler.transform(val_df[numeric_features])\n",
    "\n",
    "# One-hot encoding categorical features\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_encoded = encoder.fit_transform(train_df[categorical_features])\n",
    "val_encoded = encoder.transform(val_df[categorical_features])\n",
    "\n",
    "# Creating encoded DataFrames\n",
    "train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "val_encoded_df = pd.DataFrame(val_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Combining numeric and categorical features\n",
    "X_train = pd.concat([train_df[numeric_features].reset_index(drop=True), train_encoded_df], axis=1)\n",
    "X_val = pd.concat([val_df[numeric_features].reset_index(drop=True), val_encoded_df], axis=1)\n",
    "\n",
    "y_train = train_df['Outcome']\n",
    "y_val = val_df['Outcome']\n",
    "\n",
    "# Training KNN model with different values of k\n",
    "best_knn_f1, best_k = 0, 0\n",
    "for k in [3, 5, 7]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    preds = knn.predict(X_val)\n",
    "    f1 = f1_score(y_val, preds)\n",
    "    print(f\"K={k}, F1 Score: {f1}\")\n",
    "    if f1 > best_knn_f1:\n",
    "        best_knn_f1, best_k = f1, k\n",
    "\n",
    "print(f\"Best K: {best_k}, Best F1 Score: {best_knn_f1}\")\n",
    "\n",
    "# Training Decision Tree model with different max_depth values\n",
    "best_dt_f1, best_depth = 0, 0\n",
    "for depth in [3, 5, 7]:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    preds = dt.predict(X_val)\n",
    "    f1 = f1_score(y_val, preds)\n",
    "    print(f\"max_depth={depth}, F1 Score: {f1}\")\n",
    "    if f1 > best_dt_f1:\n",
    "        best_dt_f1, best_depth = f1, depth\n",
    "\n",
    "print(f\"Best max_depth: {best_depth}, Best F1 Score: {best_dt_f1}\")\n",
    "\n",
    "# Selecting the best model\n",
    "best_model = knn if best_knn_f1 > best_dt_f1 else dt\n",
    "\n",
    "def inference(sample):\n",
    "    sample_numeric = scaler.transform(sample[numeric_features])\n",
    "    sample_categorical = encoder.transform(sample[categorical_features])\n",
    "    sample_transformed = pd.concat([pd.DataFrame(sample_numeric), pd.DataFrame(sample_categorical)], axis=1)\n",
    "    return best_model.predict(sample_transformed)\n",
    "\n",
    "# Running inference on sample validation data\n",
    "for i in range(5):\n",
    "    sample = val_df.iloc[[i]]\n",
    "    print(f\"Sample {i + 1} Prediction: {inference(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bbbd23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
